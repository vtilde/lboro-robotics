{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8c72f-71eb-40a9-b102-21c550502d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b08b744a91247d7beabe45dd04e9479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='30%'), Image(value=b'', format='jpeg', width='30%')), la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-30 11:44:55 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-04-30 11:44:55 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-04-30 11:44:55 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-04-30 11:44:57 UTC][ZED][INFO] [Init]  Depth mode: ULTRA\n",
      "[2025-04-30 11:44:57 UTC][ZED][INFO] [Init]  Camera successfully opened.\n",
      "[2025-04-30 11:44:57 UTC][ZED][INFO] [Init]  Camera FW version: 1523\n",
      "[2025-04-30 11:44:57 UTC][ZED][INFO] [Init]  Video mode: VGA@100\n",
      "[2025-04-30 11:44:57 UTC][ZED][INFO] [Init]  Serial Number: S/N 30505807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628/3293474440.py:294: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"follower.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.74, Sharp: 0.50, FPS: 448.9\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.55, Sharp: 0.50, FPS: 224.6\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.45, Sharp: 0.50, FPS: 151.1\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.36, Sharp: 0.71, FPS: 114.3\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.30, Sharp: 0.98, FPS: 92.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.35, Sharp: 0.74, FPS: 77.2\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.37, Sharp: 0.65, FPS: 66.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.32, Sharp: 0.89, FPS: 59.0\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.31, Sharp: 0.95, FPS: 52.9\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.49, Sharp: 0.56, FPS: 47.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.51, Sharp: 0.18, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.52, Sharp: 0.16, FPS: 3.7\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.52, Sharp: 0.25, FPS: 3.7\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.50, Sharp: 0.26, FPS: 3.7\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.49, Sharp: 0.17, FPS: 3.8\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.33, Sharp: 0.83, FPS: 4.0\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.33, Sharp: 0.87, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.62, Sharp: 0.58, FPS: 3.6\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.66, Sharp: 1.03, FPS: 3.5\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.43, Sharp: 0.35, FPS: 3.5\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.39, Sharp: 0.55, FPS: 3.5\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.35, Sharp: 0.77, FPS: 3.5\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.29, Sharp: 1.03, FPS: 3.5\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.48, Sharp: 0.35, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.52, Sharp: 0.47, FPS: 3.2\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.59, Sharp: 0.48, FPS: 3.2\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.25, Sharp: 1.26, FPS: 3.4\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.28, Sharp: 1.12, FPS: 3.6\n",
      "Low visibility (0/1000.0) - using guided navigation\n",
      "Low visibility (0/920.0) - using guided navigation\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.09, Sharp: 2.03, FPS: 3.4\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.35, Sharp: 0.74, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.61, Sharp: 0.80, FPS: 3.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.66, Sharp: 1.05, FPS: 3.2\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.26, Sharp: 1.18, FPS: 3.2\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.27, Sharp: 1.17, FPS: 3.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.55, Sharp: 0.86, FPS: 2.9\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.60, Sharp: 1.00, FPS: 2.9\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.56, Sharp: 1.00, FPS: 3.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.53, Sharp: 1.00, FPS: 3.1\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.52, Sharp: 0.61, FPS: 3.2\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.49, Sharp: 0.42, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.46, Sharp: 0.50, FPS: 3.7\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.45, Sharp: 0.40, FPS: 3.7\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.45, Sharp: 0.25, FPS: 3.7\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.44, Sharp: 0.28, FPS: 4.0\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.48, Sharp: 0.12, FPS: 4.2\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.50, Sharp: 0.04, FPS: 4.2\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.52, Sharp: 0.11, FPS: 4.3\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.54, Sharp: 0.22, FPS: 4.4\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.58, Sharp: 0.42, FPS: 4.4\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.62, Sharp: 0.62, FPS: 4.4\n",
      "🚀 Maximum straight-line speed\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.64, Sharp: 0.71, FPS: 4.3\n",
      "🚀 Maximum straight-line speed\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.72, Sharp: 1.40, FPS: 4.2\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.48, Sharp: 0.17, FPS: 4.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.41, Sharp: 0.44, FPS: 4.0\n",
      "Low visibility (15/990.0757782181479) - using guided navigation\n",
      "Low visibility (0/910.8697159606961) - using guided navigation\n",
      "Low visibility (0/838.0001386838404) - using guided navigation\n",
      "Low visibility (0/770.9601275891332) - using guided navigation\n",
      "Low visibility (0/709.2833173820026) - using guided navigation\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Low visibility (1/700) - using guided navigation\n",
      "Low visibility (1/700) - using guided navigation\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.92, Sharp: 2.71, FPS: 2.5\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.53, Sharp: 1.00, FPS: 2.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.46, Sharp: 1.00, FPS: 2.5\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.42, Sharp: 1.00, FPS: 2.6\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.41, Sharp: 1.00, FPS: 2.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.44, Sharp: 1.00, FPS: 2.9\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.20, Sharp: 1.48, FPS: 3.0\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.16, Sharp: 1.69, FPS: 3.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.45, Sharp: 1.00, FPS: 3.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.46, Sharp: 1.00, FPS: 3.2\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.36, Sharp: 0.71, FPS: 3.4\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.19, Sharp: 1.55, FPS: 3.6\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.24, Sharp: 1.32, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.47, Sharp: 0.35, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.54, Sharp: 0.44, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.54, Sharp: 0.66, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.53, Sharp: 0.64, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.55, Sharp: 0.38, FPS: 3.6\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.56, Sharp: 0.42, FPS: 3.9\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.56, Sharp: 0.58, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.58, Sharp: 0.59, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.60, Sharp: 0.52, FPS: 3.8\n",
      "🚀 Maximum straight-line speed\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.68, Sharp: 1.19, FPS: 4.0\n",
      "Right turn (standard enhanced)\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.25, Sharp: 1.24, FPS: 4.0\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.45, Sharp: 0.29, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.48, Sharp: 0.30, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.37, Sharp: 0.67, FPS: 3.8\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.22, Sharp: 1.41, FPS: 3.7\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.28, Sharp: 1.08, FPS: 3.5\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.55, Sharp: 0.58, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.60, Sharp: 0.60, FPS: 3.3\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.66, Sharp: 1.05, FPS: 3.3\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.38, Sharp: 0.60, FPS: 3.1\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.33, Sharp: 0.86, FPS: 3.3\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.28, Sharp: 1.08, FPS: 3.6\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.38, Sharp: 0.59, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.45, Sharp: 0.64, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.48, Sharp: 0.51, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.50, Sharp: 0.33, FPS: 3.6\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.52, Sharp: 0.32, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.56, Sharp: 0.31, FPS: 3.8\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.60, Sharp: 0.52, FPS: 3.8\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.72, Sharp: 1.40, FPS: 4.0\n",
      "Right turn (standard enhanced)\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.67, Sharp: 1.08, FPS: 3.7\n",
      "Right turn (standard enhanced)\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.22, Sharp: 1.38, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.42, Sharp: 0.43, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.51, Sharp: 0.42, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.54, Sharp: 0.42, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.58, Sharp: 0.42, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.62, Sharp: 0.62, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.65, Sharp: 0.98, FPS: 3.3\n",
      "Right turn detection boosted due to line position\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.68, Sharp: 1.17, FPS: 3.4\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.35, Sharp: 0.74, FPS: 3.2\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.30, Sharp: 1.01, FPS: 3.5\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.42, Sharp: 0.39, FPS: 3.5\n",
      "Low visibility (902/999.0870241833491) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.05, Sharp: 2.24, FPS: 3.5\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.21, Sharp: 1.47, FPS: 3.4\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.47, Sharp: 1.00, FPS: 3.2\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.54, Sharp: 0.86, FPS: 3.3\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.62, Sharp: 0.82, FPS: 3.3\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.19, Sharp: 1.56, FPS: 3.3\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.27, Sharp: 1.14, FPS: 3.3\n",
      "Dir: 1, Conf: 1.00, Line pos: 0.44, Sharp: 0.73, FPS: 3.0\n",
      "Dir: 2, Conf: 1.00, Line pos: 0.50, Sharp: 0.77, FPS: 3.0\n",
      "Right turn (standard enhanced)\n",
      "Dir: 0, Conf: 1.00, Line pos: 0.61, Sharp: 1.00, FPS: 2.8\n",
      "Low visibility (0/971.8128566070892) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (0/894.0678280785221) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (0/822.5424018322403) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (0/756.7390096856611) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (18/700) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (0/700) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (1/700) - using guided navigation\n",
      "Low visibility (193/700) - using guided navigation\n",
      "Strong right recovery during low visibility\n",
      "Low visibility (66/700) - using guided navigation\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import time\n",
    "import motors\n",
    "import cv2\n",
    "import pyzed.sl as sl\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import motors\n",
    "\n",
    "def extract_yellow(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_bound = np.array([30,40,120])\n",
    "    upper_bound = np.array([75, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "    return cv2.bitwise_and(frame, frame, mask=mask), mask\n",
    "\n",
    "def centre_rope(frame, mask):\n",
    "    contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        x,y,w,h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        rope_centre_x = x + w // 2\n",
    "        #return cropped_image, (centre_x, centre_y)\n",
    "        return rope_centre_x, mask\n",
    "    return None, mask\n",
    "\n",
    "#create widgets for the displaying of the image\n",
    "display_color = widgets.Image(format='jpeg', width='30%') #determine the width of the color image\n",
    "display_depth = widgets.Image(format='jpeg', width='30%')  #determine the width of the depth image\n",
    "layout=widgets.Layout(width='100%')\n",
    "sidebyside = widgets.HBox([display_color, display_depth],layout=layout) #horizontal \n",
    "display(sidebyside)\n",
    "\n",
    "class Camera():\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA #VGA(672*376), HD720(1280*720), HD1080 (1920*1080) or ...\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA  # Use ULTRA depth mode\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER  # Use meter units (for depth measurements)\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS: #Ensure the camera has opened succesfully\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "         # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width,self.height,sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C4, sl.MEM.CPU)\n",
    "        self.output = None\n",
    "        self.color_value = None\n",
    "\n",
    "        self.count = 0\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "           \n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "                # Retrieve colored point cloud. Point cloud is aligned on the left image.\n",
    "                self.zed.retrieve_measure(self.point_cloud, sl.MEASURE.XYZRGBA)\n",
    "\n",
    "                self.color_value = self.image.get_data()\n",
    "                cv2.putText(self.color_value, 'o', (self.width//2,self.height//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                display_color.value = bgr8_to_jpeg(self.color_value)\n",
    "\n",
    "                \n",
    "                #self.output.write(self.color_value)\n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "                depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(self.depth_image, alpha=0.03), cv2.COLORMAP_JET) \n",
    "                cv2.putText(depth_colormap, str(self.depth_image[self.height//2,self.width//2]), (self.width//2,self.height//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                display_depth.value = bgr8_to_jpeg(depth_colormap)\n",
    "                \n",
    "                # # We measure the distance camera - object using Euclidean distance\n",
    "                x = round(self.width / 2)\n",
    "                y = round(self.height / 2)\n",
    "                err, point_cloud_value = self.point_cloud.get_value(x, y)  \n",
    "                # Your mission here \n",
    "    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread       \n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread    \n",
    "            self.output.release() \n",
    "\n",
    "    def get_image(self):\n",
    "        image = self.color_value\n",
    "        return image\n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "\n",
    "def move_robot(pred_direction, confidence=None, turn_sharpness=None):\n",
    "    # Enhanced base parameters for better performance\n",
    "    forward_speed = 0.7     # Significantly increased (was 0.45) for faster straight movement\n",
    "    forward_time = 0.12      # Slightly reduced for more responsive updates\n",
    "    \n",
    "    # Turn parameters - adjusted for better handling of sharp turns\n",
    "    left_speed = 0.32# Slightly increased (was 0.25)\n",
    "    left_time = 0.14         # Slightly increased for more deliberate turns\n",
    "    right_speed = 0.32       # Significantly increased (was 0.35) to handle right turns better\n",
    "    right_time = 0.14        # Increased duration for right turns (was 0.15)\n",
    "    \n",
    "    # Convert direction history to turn sharpness if not provided\n",
    "    if turn_sharpness is None and 'direction_history' in globals():\n",
    "        turn_sharpness = 0.5  # Default medium sharpness\n",
    "    \n",
    "    # Enhanced dynamic speed adjustments based on turn sharpness and confidence\n",
    "    if turn_sharpness is not None:\n",
    "        if turn_sharpness > 0.7:  # Sharp turn - stronger adjustment\n",
    "            left_speed = max(0.22, left_speed * 0.85)\n",
    "            left_time = min(0.22, left_time * 1.4)\n",
    "            right_speed = max(0.35, right_speed * 0.9)\n",
    "            right_time = min(0.30, right_time * 1.5)  # Much longer time for sharp right turns\n",
    "            forward_speed = max(0.3, forward_speed * 0.6)  # Significant deceleration before turns\n",
    "        elif turn_sharpness < 0.3:  # Gentle turn or straight - maximize speed\n",
    "            left_speed = min(0.38, left_speed * 1.25)\n",
    "            left_time = max(0.08, left_time * 0.8)\n",
    "            right_speed = min(0.50, right_speed * 1.1)\n",
    "            right_time = max(0.14, right_time * 0.9)\n",
    "            forward_speed = min(0.9, forward_speed * 1.3)  # Boost straight-line speed significantly\n",
    "    \n",
    "    # Special handling for right turns based on confidence\n",
    "    if confidence is not None and pred_direction == 2:  # Right turn\n",
    "        # Low confidence = stronger correction\n",
    "        if confidence < 0.7:  # Increased threshold (was 0.6)\n",
    "            right_speed = min(0.6, right_speed * 1.3)  # Stronger turn (was 1.3)\n",
    "            right_time = min(0.35, right_time * 1.4)   # Longer turn (was 1.4)\n",
    "        # Higher confidence but not certain\n",
    "        elif confidence < 0.85:\n",
    "            right_speed = min(0.55, right_speed * 1.2)\n",
    "            right_time = min(0.30, right_time * 1.3)\n",
    "    \n",
    "    # Execute the appropriate movement with enhanced strategies\n",
    "    if pred_direction == 0:  # Forward\n",
    "        # Check if we're coming from a turn and need to accelerate gradually\n",
    "        was_turning = False\n",
    "        if 'direction_history' in globals() and len(direction_history) > 0:\n",
    "            was_turning = direction_history[0] != 0\n",
    "        \n",
    "        if was_turning:\n",
    "            # Gradual acceleration after a turn\n",
    "            robot.forward(forward_speed * 0.6)\n",
    "            time.sleep(forward_time * 0.5)\n",
    "            robot.forward(forward_speed * 0.8)\n",
    "            time.sleep(forward_time * 0.5)\n",
    "        \n",
    "        # Full speed on straight sections\n",
    "        robot.forward(forward_speed)\n",
    "        time.sleep(forward_time)\n",
    "        \n",
    "        # Maintain momentum between forward movements\n",
    "        robot.forward(forward_speed * 0.7)  # Higher coasting speed (was 0.5)\n",
    "        return\n",
    "    \n",
    "    elif pred_direction == 1:  # Left turn\n",
    "        # Pre-emptive deceleration for smoother left turns\n",
    "        robot.forward(forward_speed * 0.4)  # Brake before turning\n",
    "        time.sleep(0.04)\n",
    "        \n",
    "        # Execute left turn with progressive speed control\n",
    "        robot.left(left_speed * 0.8)\n",
    "        time.sleep(left_time * 0.3)\n",
    "        robot.left(left_speed)\n",
    "        time.sleep(left_time * 0.7)\n",
    "        \n",
    "        # Gradual stop for smoother motion\n",
    "        robot.left(left_speed * 0.4)\n",
    "        time.sleep(0.03)\n",
    "        robot.stop()\n",
    "        return\n",
    "    \n",
    "    elif pred_direction == 2:  # Right turn - enhanced with multi-stage approach\n",
    "        # Strong pre-emptive deceleration for right turns\n",
    "        robot.forward(forward_speed * 0.3)  # Significant brake before turning\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "        # Two-phase right turn for sharper corners\n",
    "        if turn_sharpness > 0.6:  # For sharp right turns\n",
    "            # Initial stronger turn phase\n",
    "            robot.right(right_speed * 0.8)\n",
    "            time.sleep(right_time * 0.6)\n",
    "            \n",
    "            # Second phase with adjusted angle\n",
    "            robot.right(right_speed * 0.7)\n",
    "            time.sleep(right_time * 0.4)\n",
    "        else:\n",
    "            # Standard right turn\n",
    "            robot.right(right_speed)\n",
    "            time.sleep(right_time)\n",
    "        \n",
    "        # Gradual stop for smoother motion\n",
    "        robot.right(right_speed * 0.3)\n",
    "        time.sleep(0.04)\n",
    "        robot.stop()\n",
    "        return\n",
    "    \n",
    "    else: \n",
    "        robot.stop()\n",
    "        return\n",
    "\n",
    "\n",
    "class LineDirectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LineDirectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 112 * 112, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 output classes (forward, left, right)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 64 * 112 * 112)  # Flatten the image tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "camera = Camera()\n",
    "camera.start()\n",
    "image_paths = []\n",
    "labels = []\n",
    "image_dir = 'images'\n",
    "categories = ['forward', 'left', 'right']\n",
    "for idx, category in enumerate(categories):\n",
    "    category_path = os.path.join(image_dir, category)\n",
    "    for filename in os.listdir(category_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_paths.append(os.path.join(category_path, filename))\n",
    "            labels.append(idx)  # 0=forward, 1=left, 2=right\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the robot (Ensure motors module is correctly imported and initialized)\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "\n",
    "# Load the trained model\n",
    "model = LineDirectionCNN() \n",
    "model.load_state_dict(torch.load(\"follower.pth\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Advanced parameters for adaptive movement control\n",
    "buffer = 0  # Direction buffer\n",
    "direction_history = [0, 0, 0, 0, 0]  # Expanded history for better pattern recognition\n",
    "confidence_history = [0.5, 0.5, 0.5]  # Track confidence values\n",
    "last_turn_time = time.time()\n",
    "turn_cooldown = 0.3  # Reduced cooldown for more responsive turning\n",
    "consecutive_same_direction = 0  # Track how many times we've gone the same direction\n",
    "speed_scale = 1.0  # Dynamic speed scaling\n",
    "last_five_directions = []  # For detecting oscillations\n",
    "oscillation_detected = False\n",
    "\n",
    "yellow_positions = []  \n",
    "max_positions = 10  \n",
    "\n",
    "adaptive_threshold = 1000  \n",
    "turn_sharpness = 0.5  \n",
    "\n",
    "# Initialize timers for performance measurement\n",
    "last_frame_time = time.time()\n",
    "fps_history = []\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    img = camera.get_image()\n",
    "\n",
    "    if img is not None:\n",
    "        # Calculate FPS for monitoring performance\n",
    "        current_time = time.time()\n",
    "        frame_time = current_time - last_frame_time\n",
    "        fps = 1.0 / max(0.001, frame_time)\n",
    "        fps_history.append(fps)\n",
    "        if len(fps_history) > 10:\n",
    "            fps_history.pop(0)\n",
    "        avg_fps = sum(fps_history) / len(fps_history)\n",
    "        last_frame_time = current_time\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Improved asymmetric cropping to better detect right turns\n",
    "        margin_width_left = 180  # Reduced left margin (was 200)\n",
    "        margin_width_right = 120  # Significantly reduced right margin (was 160)\n",
    "        margin_height = 200      # Reduced top margin to see further ahead (was 220)\n",
    "        cropped_image = img[margin_height:, margin_width_left:w-margin_width_right]\n",
    "\n",
    "        h, w = cropped_image.shape[:2]\n",
    "        \n",
    "        # Extract the yellow line\n",
    "        frame, mask = extract_yellow(cropped_image)\n",
    "        \n",
    "        # Calculate yellow line position for turn sharpness detection\n",
    "        yellow_center, mask = centre_rope(frame, mask)\n",
    "        if yellow_center is not None:\n",
    "            normalized_position = yellow_center / w  # 0.0 (left) to 1.0 (right)\n",
    "            yellow_positions.append(normalized_position)\n",
    "            if len(yellow_positions) > max_positions:\n",
    "                yellow_positions.pop(0)\n",
    "                \n",
    "            # Enhanced turn sharpness calculation with position trend analysis\n",
    "            if len(yellow_positions) > 3:\n",
    "                position_variance = np.var(yellow_positions)\n",
    "                # Increase sensitivity to variance\n",
    "                turn_sharpness = min(1.0, position_variance * 25)  # Increased from *20\n",
    "                \n",
    "                # Calculate position trend to detect developing turns early\n",
    "                position_trend = 0\n",
    "                for i in range(len(yellow_positions)-1):\n",
    "                    position_trend += (yellow_positions[i+1] - yellow_positions[i])\n",
    "                \n",
    "                # Amplify turn sharpness for rapidly developing turns\n",
    "                if abs(position_trend) > 0.15:  # Threshold for rapid position change\n",
    "                    turn_sharpness = min(1.0, turn_sharpness * 1.3)\n",
    "                    \n",
    "                # Enhanced edge detection: more aggressive when line is very far to right or left\n",
    "                edge_factor = 5 * abs(normalized_position - 0.5)  # Increased from 4*\n",
    "                \n",
    "                # Special handling for right side positioning (preemptive right turn detection)\n",
    "                if normalized_position > 0.65:  # Line shifting to right side\n",
    "                    edge_factor *= 1.3  # Amplify edge factor for right side\n",
    "                    \n",
    "                turn_sharpness = max(turn_sharpness, edge_factor)\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)   \n",
    "    \n",
    "        # Dynamic threshold based on recent history\n",
    "        threshold = adaptive_threshold\n",
    "        sum_pixel_values = np.sum(mask) / 255\n",
    "        \n",
    "        # Enhanced line loss handling with right-turn bias\n",
    "        if sum_pixel_values < threshold:\n",
    "            print(f\"Low visibility ({sum_pixel_values:.0f}/{threshold}) - using guided navigation\")\n",
    "            \n",
    "            # Analyze position history and trending for better recovery\n",
    "            right_bias = False\n",
    "            if yellow_positions and len(yellow_positions) >= 3:\n",
    "                # Check if line was trending toward right before disappearing\n",
    "                if yellow_positions[-1] > 0.55 or (yellow_positions[-1] > yellow_positions[-3] + 0.1):\n",
    "                    right_bias = True\n",
    "            \n",
    "            # More aggressive right turn recovery\n",
    "            if right_bias or (direction_history and direction_history[0] == 2):\n",
    "                move_robot(2, 0.4, 0.9)  # Lower confidence, higher sharpness for right recovery\n",
    "                print(\"Strong right recovery during low visibility\")\n",
    "            elif direction_history and direction_history[0] == 1:\n",
    "                move_robot(1, 0.6, 0.7)  # Slightly more aggressive left recovery\n",
    "            else:\n",
    "                # Default with slight right bias (since right turns are problematic)\n",
    "                last_non_forward = next((d for d in direction_history if d != 0), 2)  # Default to right\n",
    "                move_robot(last_non_forward, 0.5, 0.6)\n",
    "            \n",
    "            # Update adaptive threshold\n",
    "            adaptive_threshold = max(700, adaptive_threshold * 0.92)\n",
    "            continue\n",
    "        else:\n",
    "            # Reset adaptive threshold toward baseline\n",
    "            adaptive_threshold = threshold * 0.9 + 1000 * 0.1\n",
    "        \n",
    "        # Prepare image for model prediction\n",
    "        pil_img = Image.fromarray(frame_rgb)\n",
    "        input_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        # Get model prediction with confidence scores\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            \n",
    "            # Get confidence scores for all directions\n",
    "            forward_conf = probabilities[0][0].item()\n",
    "            left_conf = probabilities[0][1].item()\n",
    "            right_conf = probabilities[0][2].item()\n",
    "            \n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "            pred_direction = predicted.item()\n",
    "            confidence_value = confidence.item()\n",
    "            \n",
    "            # Enhanced right-turn detection: Boost right turn likelihood when near right edge\n",
    "            if yellow_center is not None:\n",
    "                right_bias = normalized_position > 0.62  # Reduced threshold (was ~0.65)\n",
    "                if right_bias and right_conf > 0.25:  # More sensitive right detection\n",
    "                    if right_conf > forward_conf * 0.7:  # If right is remotely competitive with forward\n",
    "                        pred_direction = 2  # Override to right turn\n",
    "                        confidence_value = max(right_conf, confidence_value * 0.9)  # Preserve confidence\n",
    "                        print(\"Right turn detection boosted due to line position\")\n",
    "        \n",
    "        # Check for direction oscillation\n",
    "        last_five_directions.append(pred_direction)\n",
    "        if len(last_five_directions) > 5:\n",
    "            last_five_directions.pop(0)\n",
    "            \n",
    "        # Enhanced oscillation detection with specific patterns\n",
    "        oscillation_detected = False\n",
    "        if len(last_five_directions) == 5:\n",
    "            # Detect standard oscillation\n",
    "            alternating = True\n",
    "            for i in range(len(last_five_directions)-1):\n",
    "                if last_five_directions[i] == last_five_directions[i+1]:\n",
    "                    alternating = False\n",
    "                    break\n",
    "            \n",
    "            # Detect right-forward oscillation (common problem pattern)\n",
    "            right_forward_oscillation = (\n",
    "                last_five_directions.count(0) >= 2 and \n",
    "                last_five_directions.count(2) >= 2 and\n",
    "                last_five_directions[0] != last_five_directions[1]\n",
    "            )\n",
    "            \n",
    "            oscillation_detected = alternating or right_forward_oscillation\n",
    "        \n",
    "        # Track consecutive same directions\n",
    "        if len(direction_history) > 0 and pred_direction == direction_history[0]:\n",
    "            consecutive_same_direction += 1\n",
    "        else:\n",
    "            consecutive_same_direction = 0\n",
    "            \n",
    "        # Update direction and confidence history\n",
    "        direction_history.pop()\n",
    "        direction_history.insert(0, pred_direction)\n",
    "        confidence_history.pop(0)\n",
    "        confidence_history.append(confidence_value)\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        avg_confidence = sum(confidence_history) / len(confidence_history)\n",
    "        \n",
    "        # Enhanced diagnostics with normalized position information\n",
    "        line_pos_str = f\"Line pos: {normalized_position:.2f}\" if yellow_center is not None else \"Line: N/A\"\n",
    "        print(f\"Dir: {pred_direction}, Conf: {confidence_value:.2f}, {line_pos_str}, Sharp: {turn_sharpness:.2f}, FPS: {avg_fps:.1f}\")\n",
    "        \n",
    "        # Decision making logic with anti-oscillation and enhanced right turn handling\n",
    "        current_time = time.time()\n",
    "        cooldown_active = (current_time - last_turn_time) < turn_cooldown\n",
    "        \n",
    "        # if oscillation_detected:\n",
    "        #     print(\"⚠️ Oscillation detected - stabilizing\")\n",
    "        #     # Stronger bias toward right turns during oscillation (since they're problematic)\n",
    "        #     if forward_conf > 0.4:\n",
    "        #         move_robot(0, forward_conf, 0.3)  # Go forward to reset\n",
    "        #     elif left_conf > right_conf:\n",
    "        #         move_robot(1, left_conf, 0.7)  # Decisive left turn\n",
    "        #     else:\n",
    "        #         move_robot(2, 0.5, 0.5)  # Default to right turn with medium sharpness\n",
    "            \n",
    "        #     # Reset oscillation detection\n",
    "        #     last_five_directions = [pred_direction] * 5\n",
    "            \n",
    "        if pred_direction == 2:  # Right turn - enhanced handling\n",
    "            # Boost confidence and commit more strongly to right turns\n",
    "            effective_confidence = min(0.75, confidence_value * 1)  # Boost confidence\n",
    "            \n",
    "            if cooldown_active and consecutive_same_direction < 2:\n",
    "                # More aggressive initial right turn to prevent missing turns\n",
    "                move_robot(2, effective_confidence, max(turn_sharpness * 1.2, 0.5))\n",
    "                print(\"Right turn (enhanced initial)\")\n",
    "            else:\n",
    "                # Stronger overall right turn with increased sharpness\n",
    "                move_robot(2, effective_confidence, max(turn_sharpness * 1.1, 0.4))\n",
    "                print(\"Right turn (standard enhanced)\")\n",
    "                \n",
    "            last_turn_time = current_time\n",
    "                \n",
    "        elif pred_direction == 1:  # Left turn - standard handling\n",
    "            if cooldown_active and consecutive_same_direction < 2:\n",
    "                move_robot(1, confidence_value, turn_sharpness * 0.9)\n",
    "            else:\n",
    "                move_robot(1, confidence_value, turn_sharpness)\n",
    "                \n",
    "            last_turn_time = current_time\n",
    "                \n",
    "        else:  # Forward movement with speed optimization\n",
    "            # Progressive speed increase on straight sections\n",
    "            if consecutive_same_direction > 6:\n",
    "                # If going straight for a while, significantly increase speed\n",
    "                move_robot(0, confidence_value, min(0.2, turn_sharpness * 0.7))  # Reduced sharpness for speed\n",
    "                if consecutive_same_direction > 10:\n",
    "                    print(\"🚀 Maximum straight-line speed\")\n",
    "            else:\n",
    "                move_robot(0, confidence_value, min(0.4, turn_sharpness))\n",
    "        \n",
    "        # Update buffer for next iteration\n",
    "        buffer = pred_direction\n",
    "        \n",
    "        # Adaptive processing rate\n",
    "        elapsed = time.time() - start_time\n",
    "        target_time = 0.025  # ~40 fps target (increased from 33fps)\n",
    "        if elapsed < target_time:\n",
    "            time.sleep(target_time - elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4c78e-8f93-4891-b0f2-e0e2282f900a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
