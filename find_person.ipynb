{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76feeff0-fa32-4a84-b782-62ff8b6980ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.yolo_model = YOLO(\"yolo11l_half.engine\")\n",
    "\n",
    "        self.classes = [0] # humans\n",
    "        self.tracked_id = None\n",
    "        self.last_position = None\n",
    "        self.lost = False\n",
    "        self.ignore_ids = []\n",
    "\n",
    "        self.redetect_within = 50\n",
    "\n",
    "    def show_all_boxes(self, image):\n",
    "        image = image[:, :, :3] # remove A channel from frame\n",
    "        result = self.yolo_model.track(image, persist=True, classes=self.classes, verbose=False)[0]\n",
    "        return self.np_to_jpeg(result.plot())\n",
    "\n",
    "\n",
    "    def track(self, image, return_type=\"xcentre\"):\n",
    "        \"\"\"Track objects in next frame of video feed\n",
    "\n",
    "        parameters\n",
    "        image (np.Array) : next frame of video (from zl.Mat().get_data())\n",
    "        return_type (String) :\n",
    "            \"centre\"  to return tuple of (xcentre, ycentre) coordinates\n",
    "            \"corners\" to return tuple of (x1, y1, x2, y2) coordinates of bounding box corners\n",
    "            \"xcentre\" to return single int for horizontal centre coordinate of bounding box\n",
    "        \"\"\"\n",
    "        self.result = self.yolo_model.track(image[:, :, :3], persist=True, classes=self.classes, verbose=False)[0]\n",
    "        if not self.lost:\n",
    "            tracked_index = self._get_tracked_index()\n",
    "            \n",
    "            if tracked_index is False:\n",
    "                # set as lost if tracked id not found\n",
    "                self.lost = True\n",
    "                return False\n",
    "            else:\n",
    "                # add other detected objects to list of ids to ignore\n",
    "                for i in self.result.boxes.id:\n",
    "                    if i != self.tracked_id:\n",
    "                        self.ignore_ids.append(i)\n",
    "                \n",
    "                self.last_position = self.result.boxes.xyxy[tracked_index]\n",
    "\n",
    "                # check return type\n",
    "                if return_type == \"centre\":\n",
    "                    return (\n",
    "                        int((self.last_position[0] + self.last_position[2]) / 2),\n",
    "                        int((self.last_position[1] + self.last_position[3]) / 2)\n",
    "                    )\n",
    "                elif return_type == \"corners\":\n",
    "                    return self.last_position\n",
    "                elif return_type == \"xcentre\":\n",
    "                    return int((self.last_position[0] + self.last_position[2]) / 2)\n",
    "        else:\n",
    "            # if lost, wait for object with similar position to reappear\n",
    "            if self.result.boxes.id is None:\n",
    "                return False\n",
    "            \n",
    "            for i in range(len(self.result.boxes.id)):\n",
    "\n",
    "                # ignore objects that appeared at the same time as original tracked object\n",
    "                if self.result.boxes.id[i] not in self.ignore_ids:\n",
    "\n",
    "                    coords = self.result.boxes.xyxy[i]\n",
    "                    print(\"new box id: \" + str(self.result.boxes.id[i]))\n",
    "                    print(\"    coords: \", coords)\n",
    "                    print(\"last known: \", self.last_position)\n",
    "                    # TODO: not redetecting, make it more lenient\n",
    "                    corners = [\n",
    "                        abs(coords[0] - self.last_position[0]) <= self.redetect_within,\n",
    "                        abs(coords[1] - self.last_position[1]) <= self.redetect_within,\n",
    "                        abs(coords[2] - self.last_position[2]) <= self.redetect_within,\n",
    "                        abs(coords[3] - self.last_position[3]) <= self.redetect_within\n",
    "                    ]\n",
    "                    print(corners)\n",
    "                    print(corners.count(True))\n",
    "                    print()\n",
    "                    if corners.count(True) >= 3:\n",
    "                        self.lost = False\n",
    "                        self.tracked_id = self.result.boxes.id[i]\n",
    "                        return self.track(image)\n",
    "\n",
    "            # if no suitable objects found\n",
    "            return False\n",
    "\n",
    "        \n",
    "\n",
    "    def _get_tracked_index(self):\n",
    "        if self.result.boxes.id is None:\n",
    "            return False\n",
    "        if self.tracked_id in self.result.boxes.id:\n",
    "            return np.where(self.result.boxes.id.numpy() == self.tracked_id)[0][0]\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def np_to_jpeg(self, data):\n",
    "        return bytes(cv2.imencode('.jpg', data)[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4234ca-7562-4b04-94c9-98749d6d8faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618063e691d54af49b211f51a660a7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='45%'), Image(value=b'', format='jpeg', width='45%')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a81d9a04eb4519b0e985e316d7e367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-30 09:02:42 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-04-30 09:02:42 UTC][ZED][INFO] Logging level INFO\n",
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "[2025-04-30 09:02:42 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-04-30 09:02:43 UTC][ZED][INFO] [Init]  Depth mode: ULTRA\n",
      "[2025-04-30 09:02:44 UTC][ZED][INFO] [Init]  Camera successfully opened.\n",
      "[2025-04-30 09:02:44 UTC][ZED][INFO] [Init]  Camera FW version: 1523\n",
      "[2025-04-30 09:02:44 UTC][ZED][INFO] [Init]  Video mode: VGA@100\n",
      "[2025-04-30 09:02:44 UTC][ZED][INFO] [Init]  Serial Number: S/N 32565960\n",
      "Loading yolo11l_half.engine for TensorRT inference...\n",
      "[04/30/2025-10:02:44] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[04/30/2025-10:02:44] [TRT] [I] Loaded engine size: 52 MiB\n",
      "[04/30/2025-10:02:44] [TRT] [W] Using an engine plan file across different models of devices is not recommended and is likely to affect performance or even cause errors.\n",
      "[04/30/2025-10:02:45] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +36, now: CPU 5, GPU 336 (MiB)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter id to track (or leave blank to skip): 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking object id 1\n",
      "(398, 117)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 62\u001b[0m\n\u001b[1;32m     57\u001b[0m     image_display\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, image)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     image_rect \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(\n\u001b[1;32m     60\u001b[0m         image,\n\u001b[1;32m     61\u001b[0m         (\u001b[38;5;28mint\u001b[39m(tracked_box[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(tracked_box[\u001b[38;5;241m1\u001b[39m])),\n\u001b[0;32m---> 62\u001b[0m         (\u001b[38;5;28mint\u001b[39m(\u001b[43mtracked_box\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m), \u001b[38;5;28mint\u001b[39m(tracked_box[\u001b[38;5;241m3\u001b[39m])),\n\u001b[1;32m     63\u001b[0m         (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m     image_display\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, image_rect)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     68\u001b[0m full_display\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mshow_all_boxes(image)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "image_display = widgets.Image(format=\"jpeg\", width=\"45%\")\n",
    "full_display = widgets.Image(format=\"jpeg\", width=\"45%\")\n",
    "display(widgets.HBox([image_display, full_display]))\n",
    "\n",
    "location_coords_display = widgets.Label()\n",
    "display(location_coords_display)\n",
    "\n",
    "import pyzed.sl as sl\n",
    "camera = sl.Camera()\n",
    "camera_params = sl.InitParameters()\n",
    "camera_params.camera_resolution = sl.RESOLUTION.VGA\n",
    "camera_params.depth_mode = sl.DEPTH_MODE.ULTRA\n",
    "camera_params.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "camera_status = camera.open(camera_params)\n",
    "if camera_status != sl.ERROR_CODE.SUCCESS:\n",
    "    print(\"camera error\")\n",
    "    print(camera_status)\n",
    "    camera.close()\n",
    "    exit()\n",
    "\n",
    "# initialize model\n",
    "m = Model()\n",
    "\n",
    "# get initial image and choose object to track\n",
    "image_mat = sl.Mat()\n",
    "started_tracking = False\n",
    "while not started_tracking:\n",
    "    err = camera.grab()\n",
    "    if err == sl.ERROR_CODE.SUCCESS:\n",
    "        camera.retrieve_image(image_mat)\n",
    "        image = image_mat.get_data()\n",
    "        \n",
    "        image_display.value = m.show_all_boxes(image)\n",
    "    \n",
    "        user_input = input(\"enter id to track (or leave blank to skip):\")\n",
    "        if user_input == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            m.tracked_id = int(user_input)\n",
    "            print(\"tracking object id \" + str(user_input))\n",
    "            started_tracking = True\n",
    "\n",
    "# start tracking\n",
    "running = True\n",
    "while running:\n",
    "    err = camera.grab()\n",
    "    if err == sl.ERROR_CODE.SUCCESS:\n",
    "        camera.retrieve_image(image_mat)\n",
    "        image = image_mat.get_data()\n",
    "\n",
    "        tracked_box = m.track(image, return_type=\"centre\")\n",
    "        print(tracked_box)\n",
    "        if tracked_box is False:\n",
    "            image_display.value = bytes(cv2.imencode('.jpg', image)[1])\n",
    "        else:\n",
    "            image_rect = cv2.rectangle(\n",
    "                image,\n",
    "                (int(tracked_box[0]), int(tracked_box[1])),\n",
    "                (int(tracked_box[2]), int(tracked_box[3])),\n",
    "                (255, 0, 0),\n",
    "                4\n",
    "            )\n",
    "            image_display.value = bytes(cv2.imencode('.jpg', image_rect)[1])\n",
    "\n",
    "        full_display.value = m.show_all_boxes(image)\n",
    "    \n",
    "\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c736d6-3371-4edc-9c74-39689b7d82b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
